from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import Any
from datetime import datetime, timedelta, timezone
import hashlib

from .. import models, schemas
from ..database import get_db
from ..services import stock_service, news_service
from ..services.ai_service import ai_client

router = APIRouter(
    prefix="/analyze",
    tags=["analyze"],
)


def generate_request_hash(tickers: list[str], query: str | None = None) -> str:
    """
    í‹°ì»¤ë“¤ì„ ì•ŒíŒŒë²³ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê²°í•©í•œ ë¬¸ìì—´ë¡œ í•´ì‹œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ìˆœì„œê°€ ë‹¬ë¼ë„ ë™ì¼í•œ ìºì‹œê°€ ë™ì‘í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    # í‹°ì»¤ë¥¼ ëŒ€ë¬¸ìë¡œ ë³€í™˜í•˜ê³  ì •ë ¬
    sorted_tickers = sorted([t.upper() for t in tickers])
    # í‹°ì»¤ë“¤ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ê²°í•©
    tickers_str = "_".join(sorted_tickers)
    # ì¿¼ë¦¬ê°€ ìˆìœ¼ë©´ í¬í•¨
    if query:
        full_str = f"{tickers_str}_{query}"
    else:
        full_str = tickers_str
    # í•´ì‹œ ìƒì„± (SHA256 ì‚¬ìš©)
    return hashlib.sha256(full_str.encode()).hexdigest()


async def fetch_ticker_data(ticker: str, db: AsyncSession) -> dict[str, Any]:
    """
    íŠ¹ì • í‹°ì»¤ì˜ ì¬ë¬´ ë°ì´í„°ì™€ ë‰´ìŠ¤ë¥¼ DBì—ì„œ ì¡°íšŒí•˜ê±°ë‚˜, ì—†ê±°ë‚˜ ì˜¤ë˜ëœ ê²½ìš° ì™¸ë¶€ APIì—ì„œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    
    - MarketReport: ìµœì‹  ë°ì´í„°ê°€ 24ì‹œê°„ ì´ë‚´ë©´ DB ì‚¬ìš©, ì•„ë‹ˆë©´ ì™¸ë¶€ API í˜¸ì¶œ
    - Financial: DBì—ì„œ ì¡°íšŒ, ì—†ìœ¼ë©´ ì™¸ë¶€ API í˜¸ì¶œ
    - Company: DBì—ì„œ ì¡°íšŒ, ì—†ìœ¼ë©´ ì™¸ë¶€ API í˜¸ì¶œ
    """
    ticker = ticker.upper()
    
    # 1. DBì—ì„œ ìµœì‹  MarketReport ì¡°íšŒ
    stmt = select(models.MarketReport).where(
        models.MarketReport.ticker == ticker,
        models.MarketReport.source_type == "daily_news"
    ).order_by(models.MarketReport.collected_at.desc()).limit(1)
    result = await db.execute(stmt)
    latest_report = result.scalar_one_or_none()
    
    # 2. DBì—ì„œ Financial ë°ì´í„° ì¡°íšŒ
    stmt = select(models.Financial).where(
        models.Financial.ticker == ticker
    ).order_by(models.Financial.year.desc(), models.Financial.quarter.desc())
    result = await db.execute(stmt)
    financials_db = result.scalars().all()
    
    # 3. DBì—ì„œ Company ì •ë³´ ì¡°íšŒ
    stmt = select(models.Company).where(models.Company.ticker == ticker)
    result = await db.execute(stmt)
    company_db = result.scalar_one_or_none()
    
    # 4. MarketReportê°€ 24ì‹œê°„ ì´ë‚´ì¸ì§€ í™•ì¸
    need_fetch_news = True
    news_data = None
    
    if latest_report:
        age_hours = (datetime.now(timezone.utc) - latest_report.collected_at).total_seconds() / 3600
        if age_hours < 24:
            # DB ë°ì´í„° ì‚¬ìš©
            need_fetch_news = False
            # raw_dataë¥¼ íŒŒì‹±í•˜ì—¬ news í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if latest_report.raw_data and latest_report.raw_data != "No news collected for this date":
                # raw_dataì—ì„œ ë‰´ìŠ¤ ì •ë³´ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
                news_data = {
                    "raw_data": latest_report.raw_data,
                    "summary_content": latest_report.summary_content,
                    "sentiment_score": latest_report.sentiment_score,
                }
            else:
                news_data = {
                    "raw_data": "No news collected",
                    "summary_content": latest_report.summary_content or "No recent news available",
                    "sentiment_score": latest_report.sentiment_score or 0.0,
                }
    
    # 5. ì™¸ë¶€ API í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°
    stock_data = None
    news_list = []
    
    if need_fetch_news or not financials_db or not company_db:
        import asyncio
        
        tasks = []
        if need_fetch_news:
            tasks.append(news_service.fetch_company_news(ticker, limit=5))
        if not financials_db or not company_db:
            tasks.append(stock_service.fetch_company_data(ticker))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        result_idx = 0
        if need_fetch_news:
            news_result = results[result_idx]
            result_idx += 1
            if not isinstance(news_result, Exception):
                news_list = news_result if isinstance(news_result, list) else []
        
        if not financials_db or not company_db:
            stock_result = results[result_idx]
            if not isinstance(stock_result, Exception):
                stock_data = stock_result
    
    # 6. ë°ì´í„° êµ¬ì„±
    # Company ì •ë³´
    if company_db:
        company_info = {
            "ticker": company_db.ticker,
            "name": company_db.name,
            "sector": company_db.sector,
            "industry": company_db.industry,
            "currency": company_db.currency,
        }
    elif stock_data:
        company_info = stock_data.get("company", {})
    else:
        company_info = {}
    
    # Financial ë°ì´í„°
    if financials_db:
        financials_list = [
            {
                "year": f.year,
                "quarter": f.quarter,
                "revenue": f.revenue,
                "net_income": f.net_income,
                "per": f.per,
                "market_cap": f.market_cap,
            }
            for f in financials_db
        ]
    elif stock_data:
        financials_list = stock_data.get("financials", [])
    else:
        financials_list = []
    
    # News ë°ì´í„° (DBì—ì„œ ê°€ì ¸ì˜¨ ê²½ìš° summary_contentì™€ raw_data ì‚¬ìš©)
    if news_data:
        # DBì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ news í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        news_list = [news_data]
    
    return {
        "company": company_info,
        "financials": financials_list,
        "news": news_list,
    }


@router.post("/matchup", response_model=schemas.MatchupResponse, summary="ê¸°ì—… ë¹„êµ ë¶„ì„ (Matchup)")
async def analyze_matchup(
    request: schemas.MatchupRequest,
    db: AsyncSession = Depends(get_db),
):
    """
    ì—¬ëŸ¬ ê¸°ì—…ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ ìŠ¹ìë¥¼ ì„ ì •í•˜ê³  ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    
    - tickers: ë¹„êµí•  ê¸°ì—… í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["AAPL", "TSLA"])
    - query: ì„ íƒì  ì§ˆë¬¸ (ì˜ˆ: "ì„±ì¥ì„± ê´€ì ì—ì„œ ë¹„êµí•´ì¤˜")
    
    ë™ì¼í•œ í‹°ì»¤ ì¡°í•©ì˜ ìš”ì²­ì€ 24ì‹œê°„ ì´ë‚´ ìºì‹œëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not request.tickers or len(request.tickers) < 2:
        raise HTTPException(
            status_code=400,
            detail="ìµœì†Œ 2ê°œ ì´ìƒì˜ í‹°ì»¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    # í‹°ì»¤ ì •ê·œí™” (ëŒ€ë¬¸ì)
    tickers = [t.upper() for t in request.tickers]
    
    print(f"â¡ï¸ [AnalyzeRouter] Matchup analysis requested for {tickers}")
    
    # 1. ìºì‹œ í™•ì¸ (request_hashë¡œ ì¡°íšŒ)
    request_hash = generate_request_hash(tickers, request.query)
    
    # 24ì‹œê°„ ì´ë‚´ì˜ ìºì‹œ í™•ì¸
    cache_cutoff = datetime.now(timezone.utc) - timedelta(hours=24)
    stmt = select(models.AIAnalysis).where(
        models.AIAnalysis.request_hash == request_hash,
        models.AIAnalysis.created_at >= cache_cutoff
    ).order_by(models.AIAnalysis.created_at.desc()).limit(1)
    
    result = await db.execute(stmt)
    cached_analysis = result.scalar_one_or_none()
    
    if cached_analysis:
        print(f"âœ… [AnalyzeRouter] Using cached analysis for {tickers}")
        cached_response = cached_analysis.response_json
        if isinstance(cached_response, dict):
            return schemas.MatchupResponse(**cached_response)
    
    # 2. ë°ì´í„° ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬)
    print(f"ğŸ“Š [AnalyzeRouter] Fetching data for {tickers}...")
    import asyncio
    
    # ëª¨ë“  í‹°ì»¤ì— ëŒ€í•´ ë³‘ë ¬ë¡œ ë°ì´í„° ìˆ˜ì§‘ (DB ìš°ì„ , í•„ìš”ì‹œ ì™¸ë¶€ API í˜¸ì¶œ)
    ticker_tasks = [fetch_ticker_data(ticker, db) for ticker in tickers]
    ticker_data_list = await asyncio.gather(*ticker_tasks, return_exceptions=True)
    
    # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ êµ¬ì„±
    tickers_data: dict[str, Any] = {}
    for ticker, data in zip(tickers, ticker_data_list):
        if isinstance(data, Exception):
            print(f"âš ï¸ Failed to fetch data for {ticker}: {data}")
            tickers_data[ticker] = {
                "company": {},
                "financials": [],
                "news": [],
            }
        else:
            tickers_data[ticker] = data
    
    # 3. AI ë¶„ì„ í˜¸ì¶œ
    print(f"ğŸ§  [AnalyzeRouter] Running AI matchup analysis...")
    try:
        ai_result = await ai_client.generate_matchup_report(tickers_data)
    except Exception as e:
        print(f"âŒ [AnalyzeRouter] AI analysis failed: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )
    
    # 4. ê²°ê³¼ë¥¼ DBì— ì €ì¥ (ìºì‹±)
    try:
        # ê¸°ì¡´ ìºì‹œê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ìƒì„±
        if cached_analysis:
            cached_analysis.response_json = ai_result
            cached_analysis.created_at = datetime.now(timezone.utc)
        else:
            new_analysis = models.AIAnalysis(
                request_hash=request_hash,
                response_json=ai_result,
                created_at=datetime.now(timezone.utc),
            )
            db.add(new_analysis)
        
        await db.commit()
        print(f"âœ… [AnalyzeRouter] Analysis result cached")
    except Exception as e:
        print(f"âš ï¸ [AnalyzeRouter] Failed to cache result: {e}")
        # ìºì‹± ì‹¤íŒ¨í•´ë„ ê²°ê³¼ëŠ” ë°˜í™˜
        await db.rollback()
    
    # 5. ì‘ë‹µ ë°˜í™˜
    return schemas.MatchupResponse(**ai_result)
